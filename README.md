# Factory Agent - Industry 4.0 Monitoring & AI Assistant

A production-ready cloud-native application for factory operations monitoring and AI-powered insights, featuring comprehensive supply chain traceability, real-time metrics, and an intelligent chatbot. Built with React, FastAPI, and deployed on Azure Container Apps.

## Project Status: Production-Ready (Phase 7 Nearly Complete)

**All core features are implemented and deployed with active CI/CD!**

- ✅ **Backend API**: 21 REST endpoints on Azure Container Apps
- ✅ **Frontend**: 5 complete pages with Tailwind CSS + Framer Motion on Azure Static Web Apps (Free tier)
- ✅ **AI Chat**: Azure AI Foundry integration with tool calling
- ✅ **Supply Chain Traceability**: End-to-end visibility (materials → suppliers → batches → orders)
- ✅ **Material-Supplier Root Cause Linkage**: Direct traceability from defects to suppliers (PR19)
- ✅ **Agent Memory System**: Cross-session context persistence for investigations and actions (PR25)
- ✅ **Authentication**: Azure AD JWT validation for admin endpoints (PR3)
- ✅ **Security**: Rate limiting, CORS, security headers, input validation, upload size limits, Azure AD auth
- ✅ **Testing**: 138 tests, 100% passing
- ✅ **Infrastructure**: Bicep templates, CI/CD active (backend: Container Apps, frontend: Static Web Apps)
- ✅ **Reliability**: Azure Blob Storage retry logic + timeout configuration (PR22)
- ✅ **Code Quality**: 99.5/10 with 100% type hint coverage

**Current Phase**: Phase 7 Nearly Complete - Frontend migrated to Azure Static Web Apps (PR36-38), cleanup pending (PR39).

## Features

### Core Capabilities
- **AI-Powered Chat**: Natural language queries with Azure AI Foundry (GPT-4, GPT-4o) and tool calling
- **Agent Memory System** (NEW - PR25): Cross-session context persistence
  - Track ongoing investigations across conversations
  - Log actions with baseline metrics for impact measurement
  - Generate shift handoff summaries
- **Real-Time Dashboards**: OEE, downtime, quality metrics with interactive charts
- **Supply Chain Traceability**:
  - Backward trace: Batch → Materials → Suppliers
  - Forward trace: Supplier → Batches → Orders
  - Material-supplier root cause linkage for quality issues
- **Machine Monitoring**: Status, performance, OEE metrics
- **Quality Management**: Defect tracking with material/supplier linkage
- **Production Tracking**: Batch tracking, order fulfillment status

### Manufacturing Metrics
- **OEE (Overall Equipment Effectiveness)**: Availability × Performance × Quality
- **Scrap Analysis**: Scrap rates by machine, defect breakdown
- **Quality Issues**: Severity-based filtering with root cause analysis
- **Downtime Analysis**: Downtime by reason, major event tracking

### Architecture Highlights
- **Async-First Backend**: FastAPI with async/await for scalability
- **Type-Safe Frontend**: React 19 + TypeScript with Tailwind CSS + Framer Motion
- **Dual Storage**: Local JSON (dev) or Azure Blob Storage (production)
- **Agent Memory Persistence**: Investigations and actions stored in Azure Blob Storage
- **Functions-First**: Maintainable code with minimal class overhead
- **Production-Ready**: Rate limiting, security headers, error handling, comprehensive logging

### Security Features (PR24C)
- **Security Headers**: X-Content-Type-Options, X-Frame-Options, X-XSS-Protection, Referrer-Policy
- **Upload Size Validation**: 50MB max upload limit to prevent DoS attacks
- **Rate Limiting**: Per-endpoint rate limits (SlowAPI)
- **Input Validation**: Pydantic models on all endpoints
- **Azure AD Auth**: JWT validation for admin endpoints
- **Prompt Injection Mitigation**: Pattern detection and logging

## Tech Stack

### Frontend
- **React 19.1** + **TypeScript 5.9** - Modern UI framework with strict mode
- **Tailwind CSS v4** - Utility-first CSS framework
- **Framer Motion** - Declarative animations
- **Lucide React** - Open-source icon library
- **Recharts 3.3** - Data visualization library
- **Axios 1.13** - HTTP client with request/response interceptors
- **Vite 7.1** - Lightning-fast build tool (replaces Create React App)
- **React Router 7.9** - Client-side routing with nested routes

### Backend
- **FastAPI 0.115+** - Async REST API framework with auto-generated docs
- **Python 3.11+** - Modern Python with type hints
- **Pydantic 2.10+** - Data validation and serialization
- **Azure OpenAI SDK 1.51+** - AI chat with AsyncAzureOpenAI client
- **Azure Blob Storage 12.15+** - Cloud data persistence (async client)
- **Azure Key Vault 4.8+** - Centralized secrets management
- **Azure Identity 1.15+** - DefaultAzureCredential for authentication
- **SlowAPI 0.1+** - Rate limiting middleware
- **python-jose 3.3+** - JWT token validation for Azure AD auth
- **httpx 0.24+** - Async HTTP client for JWKS fetching
- **aiofiles 24.1+** - Async file I/O
- **pytest 7.4+** - Testing framework

### Deployment
- **Azure Static Web Apps** - Frontend hosting (Free tier)
- **Azure Container Apps** - Backend hosting (consumption plan)
- **Azure Container Registry** - Docker image storage (backend only)
- **GitHub Actions** - CI/CD workflows (active)
- **Docker + Docker Compose** - Backend containerization
- **Azure Bicep** - Infrastructure as Code templates

## Quick Start

### Using Docker Compose (Recommended for Backend)

```bash
# 1. Clone and configure
git clone <repository-url>
cd factory-agent
cp .env.example .env
# Edit .env with your Azure AI Foundry credentials

# 2. Start backend
docker-compose up --build

# 3. Start frontend separately (in another terminal)
cd frontend
npm install
npm run dev

# 4. Access the application
# - Frontend: http://localhost:5173
# - Backend API: http://localhost:8000
# - API Docs: http://localhost:8000/docs
```

**Note**: Docker Compose currently only runs the backend. Frontend must be run separately with `npm run dev`.

### Manual Setup

**Backend:**
```bash
cd backend
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate
pip install -r requirements.txt

# Generate test data
python -c "import asyncio; from shared.data_generator import generate_production_data; asyncio.run(generate_production_data(30))"

# Start server
uvicorn src.api.main:app --reload --host 0.0.0.0 --port 8000
```

**Frontend:**
```bash
cd frontend
npm install
npm run dev  # Development server on port 5173
```

### Azure AI Foundry Configuration

Create a `.env` file (copy from `.env.example`):

```bash
# Azure AI Foundry (Required for AI chat)
# Endpoint format: https://your-resource.cognitiveservices.azure.com/ (OpenAI-compatible)
# OR: https://your-resource.services.ai.azure.com/api/projects/your-project (AI Foundry format)
AZURE_ENDPOINT=https://your-resource.cognitiveservices.azure.com/
AZURE_API_KEY=your-api-key
AZURE_DEPLOYMENT_NAME=gpt-4o  # or gpt-4, gpt-35-turbo
AZURE_API_VERSION=2024-08-01-preview

# Storage (Optional - defaults to local JSON)
STORAGE_MODE=local  # Use 'local' for development, 'azure' for production
AZURE_STORAGE_CONNECTION_STRING=<your-connection-string>
AZURE_BLOB_CONTAINER=factory-data

# Azure AD Authentication (Optional - for POST /api/setup endpoint)
AZURE_AD_TENANT_ID=your-azure-ad-tenant-id
AZURE_AD_CLIENT_ID=your-app-registration-client-id

# Azure Key Vault (Optional - for production secrets management)
# Leave empty to use environment variables directly
KEYVAULT_URL=https://your-vault-name.vault.azure.net/

# Application
DEBUG=false  # Set to 'true' for detailed error messages (development only)
ALLOWED_ORIGINS=http://localhost:3000,http://localhost:5173,http://localhost:5174
RATE_LIMIT_CHAT=10/minute
RATE_LIMIT_SETUP=5/minute
```

**Using Azure Key Vault (Optional - Recommended for Production):**

Azure Key Vault provides secure, centralized storage for application secrets:

1. **Create Key Vault** (see [docs/AZURE_KEYVAULT_SETUP.md](docs/AZURE_KEYVAULT_SETUP.md)):
   ```bash
   az keyvault create --name factory-agent-kv \
     --resource-group factory-agent-rg \
     --location eastus
   ```

2. **Upload secrets** using the helper script:
   ```bash
   ./scripts/upload_secrets_to_keyvault.sh factory-agent-kv
   ```

3. **Configure the application**:
   ```bash
   KEYVAULT_URL=https://factory-agent-kv.vault.azure.net/
   ```

4. **Benefits**:
   - No API keys in code or configuration files
   - Secret rotation without code changes
   - Audit trail for secret access
   - Works seamlessly with Managed Identity in Azure

For detailed setup instructions, see [docs/AZURE_KEYVAULT_SETUP.md](docs/AZURE_KEYVAULT_SETUP.md).

**Getting Azure AD credentials (Optional):**
1. Go to [Azure Portal](https://portal.azure.com)
2. Navigate to **Azure Active Directory** → **App registrations**
3. Create a new app registration or select existing
4. Copy **Directory (tenant) ID** → use as `AZURE_AD_TENANT_ID`
5. Copy **Application (client) ID** → use as `AZURE_AD_CLIENT_ID`
6. Configure **Authentication** → Add platform → Single-page application → Add `http://localhost:5173` as redirect URI

**Note**: Authentication is only required for the `POST /api/setup` endpoint (data generation). All GET endpoints work without authentication.

**Getting Azure AI Foundry credentials:**
1. Go to [Azure AI Foundry Portal](https://ai.azure.com)
2. Navigate to your project
3. Go to **Project Settings**
4. Copy **Endpoint** - Both formats are supported:
   - `.cognitiveservices.azure.com` (OpenAI-compatible endpoint)
   - `.services.ai.azure.com/api/projects/your-project` (AI Foundry project endpoint)
5. Go to **Keys** section and copy an API key
6. Set your **Deployment Name** (e.g., `gpt-4o`, `gpt-4`, `gpt-35-turbo`)

## Usage

### 1. Generate Test Data

First time setup - generate 30 days of synthetic factory data:

```bash
# Using the API
curl -X POST http://localhost:8000/api/setup

# Or specify custom days
curl -X POST http://localhost:8000/api/setup -H "Content-Type: application/json" -d '{"days": 30}'
```

This creates realistic production data with planted scenarios for demonstration.

### 2. Access the Web Interface

Open your browser to **http://localhost:5173**

**5 Available Pages:**
1. **Dashboard** - OEE gauges, downtime charts, quality metrics
2. **Machines** - Machine status cards with performance metrics
3. **Alerts** - Quality issues with material/supplier root cause linkage
4. **Traceability** - 3-tab interface:
   - Batch Lookup: Trace materials and suppliers
   - Supplier Impact: Analyze supplier quality impact
   - Order Status: Track order fulfillment
5. **Chat** - AI assistant for natural language queries

### 3. API Endpoints

**Metrics:**
- `GET /api/metrics/oee` - OEE metrics
- `GET /api/metrics/scrap` - Scrap analysis
- `GET /api/metrics/quality` - Quality issues with material linkage
- `GET /api/metrics/downtime` - Downtime analysis

**Traceability:**
- `GET /api/suppliers` - List suppliers with quality metrics
- `GET /api/suppliers/{id}` - Supplier details
- `GET /api/suppliers/{id}/impact` - Supplier quality impact analysis
- `GET /api/batches` - List production batches
- `GET /api/batches/{id}` - Batch details with materials
- `GET /api/traceability/backward/{batch_id}` - Backward trace (batch → suppliers)
- `GET /api/traceability/forward/{supplier_id}` - Forward trace (supplier → orders)
- `GET /api/orders` - List customer orders
- `GET /api/orders/{id}` - Order details
- `GET /api/orders/{id}/batches` - Order batches with production summary

**Data Management:**
- `POST /api/setup` - Generate synthetic data (requires Azure AD authentication)
- `GET /api/stats` - Data statistics
- `GET /api/machines` - List machines
- `GET /api/date-range` - Data date range

**AI Chat:**
- `POST /api/chat` - AI-powered chat with tool calling
  ```json
  {
    "message": "What was the OEE last week?",
    "history": []
  }
  ```

**System:**
- `GET /health` - Health check endpoint

**Full API documentation:** http://localhost:8000/docs

### 4. Example Chat Queries

The AI assistant can answer questions like:
- "What was our OEE this week?"
- "Which supplier caused quality issues on Day 15?"
- "Show me all materials from ComponentTech Industries"
- "Which machine had the most downtime?"
- "Trace batch BATCH-20251015-003 to its suppliers"
- "What orders are delayed?"

## Project Structure

```
factory-agent/
├── backend/                    # FastAPI backend
│   ├── src/
│   │   └── api/
│   │       ├── main.py        # App entry, CORS, rate limiting
│   │       ├── auth.py        # Azure AD JWT validation (NEW - PR3)
│   │       └── routes/        # API endpoints
│   │           ├── metrics.py      # OEE, scrap, quality, downtime
│   │           ├── chat.py         # AI chat with tool calling
│   │           ├── traceability.py # Supply chain endpoints
│   │           └── data.py         # Data management
│   ├── requirements.txt
│   └── Dockerfile
│
├── frontend/                   # React frontend
│   ├── src/
│   │   ├── pages/             # 5 main pages
│   │   │   ├── DashboardPage.tsx
│   │   │   ├── MachinesPage.tsx
│   │   │   ├── AlertsPage.tsx
│   │   │   ├── TraceabilityPage.tsx
│   │   │   └── ChatPage.tsx
│   │   ├── components/        # Reusable UI components
│   │   ├── api/
│   │   │   └── client.ts      # Type-safe API client
│   │   └── types/
│   │   │       └── api.ts         # TypeScript interfaces
│   ├── package.json
│   └── Dockerfile
│
├── shared/                     # Shared Python modules
│   ├── models.py              # Pydantic data models (incl. Investigation, Action, MemoryStore)
│   ├── metrics.py             # Analysis functions
│   ├── data.py                # Data storage (JSON + Azure Blob)
│   ├── data_generator.py      # Synthetic data generation
│   ├── chat_service.py        # Azure AI Foundry integration
│   ├── blob_storage.py        # Azure Blob Storage client (upload validation)
│   ├── memory_service.py      # Agent memory persistence (NEW - PR25)
│   └── config.py              # Configuration + Azure Key Vault integration
│
├── tests/                      # Test suite (138 tests, 11 files)
│   ├── test_*.py              # Unit & integration tests
│   └── conftest.py            # Shared fixtures
│
├── infra/                      # Infrastructure as Code
│   ├── main.bicep             # Azure Container Apps template
│   └── main.bicepparam        # Deployment parameters
│
├── .github/workflows/          # CI/CD automation
│   ├── deploy-backend.yml     # Backend deployment
│   └── deploy-frontend.yml    # Frontend deployment
│
├── docs/                       # Documentation
│   ├── DEPLOYMENT.md          # Deployment guide
│   ├── INSTALL.md             # Installation instructions
│   ├── ROADMAP.md             # Project roadmap
│   ├── AZURE_KEYVAULT_SETUP.md # Key Vault setup guide
│   └── archive/               # Historical documentation
│
├── scripts/                    # Helper scripts
│   └── upload_secrets_to_keyvault.sh # Key Vault secret upload
│
├── docker-compose.yml         # Local development setup
├── implementation-plan.md     # Project implementation plan
└── README.md                  # This file
```

## Data Flow

### Frontend → Backend → AI
```
React Component
  → API Client (Axios)
    → FastAPI Endpoint
      → Pydantic Validation
        → Business Logic (shared/metrics.py)
          → Data Layer (JSON or Azure Blob)
            → Response (Pydantic model)
              → JSON Serialization
                → React Component State
                  → Tailwind CSS + Recharts Visualization
```

### AI Chat Flow
```
User Message
  → POST /api/chat
    → chat_service.py
      → Azure AI Foundry (AsyncAzureOpenAI)
        → Tool Calling (AI selects tools)
          → execute_tool() routes to metrics functions
            → Data retrieval from storage
              → Tool results back to Azure AI Foundry
                → AI synthesizes response
                  → Updated conversation history
                    → Response to frontend
```

## Key Features Explained

### Material-Supplier Root Cause Linkage (PR19)

Quality issues now link directly to materials and suppliers:

```json
{
  "type": "material",
  "description": "Material quality",
  "severity": "High",
  "date": "2025-10-15",
  "machine": "Assembly-001",
  "material_id": "MAT-008",
  "lot_number": "LOT-20251023-019",
  "supplier_id": "SUP-004",
  "supplier_name": "ComponentTech Industries",
  "root_cause": "supplier_quality"
}
```

**Benefits:**
- Instant root cause identification
- Quarantine decisions based on supplier quality
- Demonstrable workflow: "This defect was caused by Lot X from Supplier Y"

### Supply Chain Traceability

**Backward Trace** (Batch → Materials → Suppliers):
- View all materials used in a production batch
- Identify which suppliers provided materials
- Highlight materials linked to quality issues

**Forward Trace** (Supplier → Batches → Orders):
- Track which batches used materials from a specific supplier
- Identify affected customer orders
- Calculate impact (defects, cost estimates)

### Dual Storage Mode

**Local Mode** (default):
- Stores `production.json` in `data/` directory
- Fast, no network latency
- Works offline
- Perfect for development

**Azure Mode**:
- Stores `production.json` in Azure Blob Storage
- Cloud persistence, durable
- Multi-instance compatible
- Production-ready

Switch modes via environment variable: `STORAGE_MODE=local` or `STORAGE_MODE=azure`

### Agent Memory System (PR25)

The memory system enables cross-session context persistence for investigations and actions:

**Data Models**:
- **Investigation**: Track ongoing issue investigations with findings, hypotheses, and status
- **Action**: Log parameter changes, maintenance, or process changes with baseline metrics for impact tracking

**Capabilities**:
- `save_investigation()`: Create new investigations linked to machines or suppliers
- `update_investigation()`: Add findings, hypotheses, or change status
- `log_action()`: Record actions with baseline metrics and expected impact
- `get_relevant_memories()`: Filter by machine, supplier, or status
- `generate_shift_summary()`: Generate handoff summaries for shift changes

**Example Use Cases**:
- "Following up on the CNC-001 investigation from yesterday..."
- "Your temperature adjustment improved OEE by 8%"
- "Here's the shift summary with 3 active investigations and 2 pending follow-ups"

**Storage**: `memory.json` blob in Azure Blob Storage (requires `STORAGE_MODE=azure`)

## Planted Scenarios

The synthetic data includes demonstration scenarios:

1. **Material Quality Issues** (Various Days): Defects linked to specific material lots and suppliers
2. **Machine Downtime Events**: Breakdowns, maintenance, changeovers
3. **Order Fulfillment Tracking**: On-time, delayed, completed orders
4. **Supplier Quality Variations**: Different suppliers with varying defect rates

## Development

### Running Tests

**Backend:**
```bash
cd backend
pytest tests/ -v                      # Run all 138 test functions
pytest --cov=src --cov-report=html    # With coverage report
pytest tests/test_traceability.py -v  # Run specific test file
```

**Test Coverage:**
- 138 test functions across 9 test files
- 3,338 lines of test code
- 100% passing (verified)

**Frontend:**
```bash
cd frontend
npm run lint           # ESLint type checking
npm run build          # TypeScript type checking
```

### Code Quality

**Backend:**
```bash
black src/ tests/      # Format code
mypy src/              # Type checking
```

**Frontend:**
```bash
npm run lint           # ESLint
npm run build          # Type checking via TypeScript
```

### Development Workflow

1. **Backend changes**: Auto-reload with `uvicorn --reload`
2. **Frontend changes**: Hot module replacement with Vite
3. **Data changes**: Regenerate with `POST /api/setup`
4. **Test changes**: Run `pytest` or `npm test`

## Deployment

### Current: Azure Static Web Apps + Container Apps (CI/CD Active)

**Status**: Frontend on Azure Static Web Apps (Free tier), backend on Azure Container Apps.

**Deployment Method**:
- **Frontend**: Azure Static Web Apps with automatic deployment via GitHub Actions
  - URL: https://gray-ground-0bab7600f.2.azurestaticapps.net
  - SKU: Free tier (100GB bandwidth/month, free SSL)
- **Backend**: Azure Container Apps with automatic deployment via GitHub Actions
- **CI/CD**: GitHub Actions workflows active and functional
- **Storage**: Azure Blob Storage (STORAGE_MODE=azure) with retry logic + timeouts
- **Infrastructure**: Bicep templates (backend.bicep, staticwebapp.bicep)

### Local Development

For local development and testing:
- Docker Compose for backend only
- Frontend runs separately with `npm run dev` on port 5173
- Backend on port 8000
- Can use local JSON storage (`STORAGE_MODE=local`) or Azure Blob Storage (`STORAGE_MODE=azure`)

**Local Development Steps**:
```bash
# Backend (Docker Compose)
docker-compose up --build

# Frontend (separate terminal)
cd frontend
npm install
npm run dev
```

See [docs/DEPLOYMENT.md](docs/DEPLOYMENT.md) for detailed deployment guide and troubleshooting.

## Known Issues

### Azure Blob Storage Retry Logic (RESOLVED - PR22)

**Status**: ✅ RESOLVED as of 2025-11-23

**Previous Issue**: Intermittent Azure Blob Storage connectivity errors with "Server error - please try again later" messages.

**Solution Implemented**:
- Exponential retry logic: 3 retries with 2s→4s→8s backoff
- Timeout configuration: 30s connection, 60s operation
- Comprehensive error handling with specific Azure error types
- 24 new blob storage tests (100% passing)

**If you still experience issues**:
1. **Local Development**: Use `STORAGE_MODE=local` for offline development
2. **Enable DEBUG**: Set `DEBUG=true` in `.env` for detailed error messages
3. **Check Azure Status**: Verify your Azure Storage account is accessible

See [PR22 summary](docs/PR21_SUMMARY.md) for full details on the retry logic implementation.

## Documentation

- **[implementation-plan.md](implementation-plan.md)** - Complete project roadmap with current phase status
- **[docs/INSTALL.md](docs/INSTALL.md)** - Detailed installation guide
- **[docs/DEPLOYMENT.md](docs/DEPLOYMENT.md)** - Deployment instructions and troubleshooting
- **[docs/AZURE_KEYVAULT_SETUP.md](docs/AZURE_KEYVAULT_SETUP.md)** - Azure Key Vault setup and configuration
- **[docs/ROADMAP.md](docs/ROADMAP.md)** - Project roadmap and future plans
- **[docs/archive/](docs/archive/)** - Historical documentation

## Design Philosophy

**Functions Over Classes**:
- Default to functions for stateless operations
- Use classes only for: data models (Pydantic), stateful clients (Azure SDK), framework patterns

**Async/Sync Split**:
- FastAPI routes: `async def` with `await` for ALL I/O operations
- CLI commands: Synchronous operations for simplicity
- Shared utilities: Match the calling context

**Type Safety**:
- Python: Type hints on all functions, Pydantic models
- TypeScript: Strict mode, no `any` types
- End-to-end type safety: TypeScript interfaces match Pydantic models

**Demo Simplicity**:
- JSON files for data (not database)
- Consolidated modules (avoid over-engineering)
- Clear > clever

## Contributing

This is a demonstration project. Key conventions:

1. **Type hints required** on all Python functions
2. **Async for FastAPI**, sync for CLI
3. **Functions first**, classes only when needed
4. **Test critical paths** (not 100% coverage)
5. **Update docs** when adding features

## License

MIT

---

**Status**: Production-ready with active CI/CD. Phase 7 nearly complete - Frontend migrated to Azure Static Web Apps. See [implementation-plan.md](implementation-plan.md) for roadmap.

**Recent Updates:**
- **2026-01-22**: PR38 Complete - GitHub Actions workflow for Static Web Apps deployment
- **2026-01-21**: PR37 Complete - Bicep templates for Static Web Apps infrastructure
- **2026-01-21**: PR36 Complete - Frontend SWA configuration (staticwebapp.config.json, security headers)
- **2026-01-21**: Phase 7 Started - Migrate frontend from Container Apps to Static Web Apps (Free tier)
- **2025-11-29**: Phase 6 Complete - Tailwind CSS migration (MUI fully removed)
- **2025-11-26**: PR25 Complete - Agent memory system with Investigation, Action, and MemoryStore models
